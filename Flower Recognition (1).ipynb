{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Flower Recognition.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPdSTb2JwB7efp7kRbGuYpz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rYPbvU0yBJa9"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","\n","#Encoding and Split data into Train/Test Sets\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical \n","from sklearn.model_selection import train_test_split\n","\n","#Tensorflow Keras CNN Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n","\n","#Plot Images\n","import matplotlib.pyplot as plt\n","\n","\n","folder_dir = '/content/drive/MyDrive/flowers'"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EaVPTL08BMh_","executionInfo":{"status":"ok","timestamp":1658320453655,"user_tz":-330,"elapsed":27850,"user":{"displayName":"Kasturi Joshi","userId":"16949538317025313274"}},"outputId":"c249f29d-3859-4833-e71d-018d7eeb8ff6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data = []\n","label = []\n","\n","SIZE = 128 #Crop the image to 128x128\n","\n","for folder in os.listdir(folder_dir):\n","    for file in os.listdir(os.path.join(folder_dir, folder)):\n","        if file.endswith(\"jpg\"):\n","            label.append(folder)\n","            img = cv2.imread(os.path.join(folder_dir, folder, file))\n","            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            im = cv2.resize(img_rgb, (SIZE,SIZE))\n","            data.append(im)\n","        else:\n","            continue"],"metadata":{"id":"9lHFa4cGBOo5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_arr = np.array(data)\n","label_arr = np.array(label)"],"metadata":{"id":"ICEISm_xBZW5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = LabelEncoder()\n","y = encoder.fit_transform(label_arr)\n","y = to_categorical(y,5)\n","X = data_arr/255"],"metadata":{"id":"XeZG74gaBcCJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)"],"metadata":{"id":"B28f1tSsB5Tg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (SIZE,SIZE,3)))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n"," \n","\n","model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\n","model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dense(5, activation = \"softmax\"))"],"metadata":{"id":"swLBSU63Bect"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        zoom_range = 0.20,\n","        width_shift_range=0.3,\n","        height_shift_range=0.3,\n","        horizontal_flip=True,\n","        vertical_flip=True)\n","\n","datagen.fit(X_train)"],"metadata":{"id":"pa0ixwtLBr3z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n","batch_size=32\n","epochs=32\n","\n","history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n","                              epochs = epochs,\n","                              validation_data = (X_test,y_test),\n","                              verbose = 1)"],"metadata":{"id":"ICRlNtt1BunL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["categories = np.sort(os.listdir(folder_dir))\n","fig, ax = plt.subplots(6,6, figsize=(25, 40))\n","\n","for i in range(6):\n","    for j in range(6):\n","        k = int(np.random.random_sample() * len(X_test))\n","        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n","            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='green')\n","            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='green')\n","            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')\n","        else:\n","            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='red')\n","            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='red')\n","            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')"],"metadata":{"id":"4PYvSJ1YGhi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YIW8qYjcGlYr"},"execution_count":null,"outputs":[]}]}